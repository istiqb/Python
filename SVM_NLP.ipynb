{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SVM_NLP",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/istiqb/Sentiment_Analysis/blob/main/SVM_NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LTV7jU6gxahg"
      },
      "source": [
        "Support Vector Machine\r\n",
        "oleh:\r\n",
        "1. Istiqamatul Badriah (G1A017013)\r\n",
        "2. Sefti Wulandari (G1A017016)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ji80CMKb2vhb"
      },
      "source": [
        "pip install sastrawi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fM5Y4kuEyEwm"
      },
      "source": [
        "!pip install -q wordcloud\r\n",
        "import wordcloud\r\n",
        "\r\n",
        "import nltk\r\n",
        "nltk.download('stopwords')\r\n",
        "nltk.download('wordnet')\r\n",
        "nltk.download('average_perceptron_tagger')\r\n",
        "nltk.download('punkt')\r\n",
        "\r\n",
        "import io\r\n",
        "import unicodedata\r\n",
        "import re\r\n",
        "import string"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HL4ZiNg_zx0o"
      },
      "source": [
        "\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import seaborn as sns\r\n",
        "import nltk \r\n",
        "from sklearn.metrics import accuracy_score\r\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\r\n",
        "from sklearn.feature_extraction.text import CountVectorizer\r\n",
        "from sklearn.preprocessing import  LabelBinarizer\r\n",
        "from nltk.corpus import stopwords\r\n",
        "from nltk.stem.porter import PorterStemmer\r\n",
        "from wordcloud import wordcloud,STOPWORDS\r\n",
        "from nltk.stem import WordNetLemmatizer\r\n",
        "from nltk.tokenize import word_tokenize,sent_tokenize\r\n",
        "from bs4 import  BeautifulSoup\r\n",
        "import spacy\r\n",
        "import pickle\r\n",
        "import re,string,unicodedata\r\n",
        "from nltk.tokenize.toktok import ToktokTokenizer\r\n",
        "from sklearn.linear_model import LogisticRegression,SGDClassifier\r\n",
        "from sklearn.naive_bayes import MultinomialNB\r\n",
        "from sklearn.svm import SVC\r\n",
        "from textblob import TextBlob\r\n",
        "from textblob import wordnet\r\n",
        "from sklearn import svm \r\n",
        "from sklearn.metrics import  classification_report,confusion_matrix,accuracy_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_r0WI8Xz05M"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_SK6kZVt1A7Y"
      },
      "source": [
        "from google.colab import files\r\n",
        "files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7G13uKtx1M8N"
      },
      "source": [
        "!mkdir -p ~/.kaggle\r\n",
        "!cp kaggle.json ~/.kaggle/\r\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7i1yoMm1WKm"
      },
      "source": [
        "!kaggle datasets download -d jessemostipak/animal-crossing"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fiGn96F1jZi"
      },
      "source": [
        "import zipfile\r\n",
        "zip_ref = zipfile.ZipFile('animal-crossing.zip','r')\r\n",
        "zip_ref.extractall('files')\r\n",
        "zip_ref.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bcCJSMz81tGU"
      },
      "source": [
        "file_path ='/content/files/user_reviews.csv'\r\n",
        "data = pd.read_csv(file_path)\r\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BUP-tzI_2agP"
      },
      "source": [
        "# Merubah keseluruhan kalimat di kolom yang dipilih menjadi huruf kecil\r\n",
        "data['text'] = data['text'].str.lower()\r\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "crCn_ezz2_Xk"
      },
      "source": [
        "y=data.grade\r\n",
        "y.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O59JlN2A3GUo"
      },
      "source": [
        "X_test = data.text.astype(str)\r\n",
        "X_test.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zsW4EIK03Pe5"
      },
      "source": [
        "import nltk\r\n",
        "from nltk.tokenize import word_tokenize\r\n",
        "nltk.download('stopwords')\r\n",
        "from nltk.corpus import stopwords\r\n",
        "stop_words = set(stopwords.words(\"indonesian\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fl50cFkvaLR0"
      },
      "source": [
        "import re\r\n",
        "import nltk\r\n",
        "nltk.download('stopwords')\r\n",
        "from nltk.corpus import stopwords\r\n",
        "from nltk.stem.porter import PorterStemmer\r\n",
        "corpus = [ ]\r\n",
        "for i in range(0, len(data)):\r\n",
        "  text = re.sub('[^a-zA-Z]', ' ', data['text'][i])\r\n",
        "  text = text.lower()\r\n",
        "  text = text.split()\r\n",
        "  ps = PorterStemmer()\r\n",
        "  text = [ps.stem(word) for word in text if not word in set(stopwords.words('english'))]\r\n",
        "  text = ' '. join(text)\r\n",
        "  corpus.append(text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0UdN90Phm8sE"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\r\n",
        "cv = CountVectorizer(max_features=1000)\r\n",
        "X = cv.fit_transform(corpus).toarray()\r\n",
        "y = data.iloc[:,1].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-DE2d9tmon4"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\r\n",
        "le = LabelEncoder()\r\n",
        "y = le.fit_transform(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Coxg-dPR6Q3M"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\r\n",
        "X_train,X_test,y_test,y_train = train_test_split(features,label,test_size = 0.20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzYFT3Lz7ekN"
      },
      "source": [
        "from sklearn.svm import SVC  \r\n",
        "svclassifier = SVC(kernel='linear')\r\n",
        "svclassifier.fit(x_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YupqQscrYZ-T"
      },
      "source": [
        "y_pred = svclassifier.predict(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfmmyIWLk11L"
      },
      "source": [
        "print(y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_YDT051OF8eG"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\r\n",
        "print('Accuracy:{}'/format(accuracy_score(y_test, y_pred)))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}